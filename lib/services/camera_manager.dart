import 'package:camera/camera.dart';
import 'package:google_mlkit_barcode_scanning/google_mlkit_barcode_scanning.dart';
import 'package:tflite_flutter/tflite_flutter.dart';
import 'package:flutter/services.dart'; // HapticFeedbackìš©
import 'dart:typed_data';
import 'dart:convert';
import 'dart:async';
import 'dart:math' as math;

class CameraManager {
  // Camera ì»¨íŠ¸ë¡¤ëŸ¬
  CameraController? _cameraController;
  
  // ML Kit ë°”ì½”ë“œ ìŠ¤ìºë„ˆ
  final BarcodeScanner _barcodeScanner = BarcodeScanner();
  
  // TensorFlow Lite ëª¨ë¸
  Interpreter? _pillModel;
  List<String>? _labels;
  Map<String, dynamic>? _modelInfo;
  
  // ì¸ì‹ ìƒíƒœ
  bool _isPillDetectionActive = false;
  bool _isBarcodeDetectionActive = false;
  bool _isPillDetectionRunning = false;
  bool _isBarcodeDetectionRunning = false;
  bool _isImageStreamActive = false;
  
  // ì½œë°±
  Function(String)? _onBarcodeDetected;
  Function(PillClassificationResult?)? _onPillDetected;
  
  // ê°ê° ë…ë¦½ì ì¸ ë§ˆì§€ë§‰ ì²˜ë¦¬ ì‹œê°„ (1ì´ˆ ê°„ê²© ì²˜ë¦¬)
  DateTime? _lastPillDetectionTime;
  DateTime? _lastBarcodeDetectionTime;
  
  // ì§„ë™ ê´€ë ¨
  Timer? _vibrationTimer;
  bool _isVibrationEnabled = true;
  
  bool get isInitialized => _cameraController?.value.isInitialized == true;
  CameraController? get cameraController => _cameraController;

  /// í†µí•© ì¹´ë©”ë¼ ì´ˆê¸°í™”
  Future<CameraInitResult> initializeCamera() async {
    try {
      print('ğŸ” Camera + ML Kit + TensorFlow Lite í†µí•© ì¹´ë©”ë¼ ì´ˆê¸°í™” ì‹œì‘');
      
      // ê¸°ì¡´ ì •ë¦¬
      await dispose();
      
      // 1. TensorFlow Lite ëª¨ë¸ ë¡œë“œ (ì•Œì•½ ì¸ì‹ìš©)
      await _loadTensorFlowLiteModel();
      
      // 2. Camera ì´ˆê¸°í™”
      await _initializeCamera();
      
      print('âœ… í†µí•© ì¹´ë©”ë¼ ì´ˆê¸°í™” ì™„ë£Œ');
      return CameraInitResult.success();
      
    } catch (e) {
      print('âŒ ì¹´ë©”ë¼ ì´ˆê¸°í™” ì‹¤íŒ¨: $e');
      await dispose();
      
      final errorStr = e.toString().toLowerCase();
      if (errorStr.contains('permission') || 
          errorStr.contains('denied') ||
          errorStr.contains('access')) {
        return CameraInitResult.permissionDenied();
      }
      
      return CameraInitResult.error('ì¹´ë©”ë¼ ì´ˆê¸°í™” ì‹¤íŒ¨: $e');
    }
  }

  /// Camera ì´ˆê¸°í™”
  Future<void> _initializeCamera() async {
    print('ğŸ“· Camera ì´ˆê¸°í™”');
    
    final cameras = await availableCameras();
    if (cameras.isEmpty) {
      throw Exception('ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ê°€ ì—†ìŠµë‹ˆë‹¤');
    }
    
    final backCamera = cameras.firstWhere(
      (camera) => camera.lensDirection == CameraLensDirection.back,
      orElse: () => cameras.first,
    );
    
    // Androidì—ì„œ ML Kit í˜¸í™˜ì„±ì„ ìœ„í•´ NV21 í¬ë§· ì‚¬ìš©
    _cameraController = CameraController(
      backCamera,
      ResolutionPreset.high,
      enableAudio: false,
      imageFormatGroup: ImageFormatGroup.nv21, // YUV420 ëŒ€ì‹  NV21 ì‚¬ìš©
    );
    
    await _cameraController!.initialize();
    
    // ì´ˆê¸°í™” í›„ ì ê¹ ëŒ€ê¸°
    await Future.delayed(Duration(milliseconds: 500));
    
    print('âœ… Camera ì´ˆê¸°í™” ì™„ë£Œ (í•´ìƒë„: ${_cameraController!.value.previewSize})');
    print('ğŸ“± ì´ë¯¸ì§€ í¬ë§·: ${_cameraController!.value.description}');
  }

  /// TensorFlow Lite ëª¨ë¸ ë¡œë“œ
  Future<void> _loadTensorFlowLiteModel() async {
    try {
      print('ğŸ¤– TensorFlow Lite ëª¨ë¸ ë¡œë”©');
      
      // ëª¨ë¸ ì •ë³´ ë¨¼ì € ë¡œë“œ
      final modelInfoString = await rootBundle.loadString('assets/models/model_info.json');
      _modelInfo = json.decode(modelInfoString);
      print('âœ… ëª¨ë¸ ì •ë³´ ë¡œë“œ ì™„ë£Œ');
      
      final labelsString = await rootBundle.loadString('assets/models/labels.txt');
      _labels = labelsString.trim().split('\n');
      print('âœ… ë¼ë²¨ ë¡œë“œ ì™„ë£Œ: ${_labels!.length}ê°œ í´ë˜ìŠ¤');
      
      // TensorFlow Lite ëª¨ë¸ ë¡œë“œ
      _pillModel = await Interpreter.fromAsset('assets/models/pill_classifier_mobile.tflite');
      
      // ëª¨ë¸ ì…ì¶œë ¥ ì •ë³´ í™•ì¸
      final inputTensors = _pillModel!.getInputTensors();
      final outputTensors = _pillModel!.getOutputTensors();
      
      print('âœ… TensorFlow Lite ëª¨ë¸ ë¡œë“œ ì™„ë£Œ');
      print('ğŸ“Š ì…ë ¥ í…ì„œ: ${inputTensors.first.shape}');
      print('ğŸ“Š ì¶œë ¥ í…ì„œ: ${outputTensors.first.shape}');
      
    } catch (e) {
      print('âŒ TensorFlow Lite ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: $e');
      throw e;
    }
  }

  /// í†µí•© ì¸ì‹ ì‹œì‘ (ë°”ì½”ë“œ + ì•Œì•½)
  void startDetection({
    Function(String)? onBarcodeDetected,
    Function(PillClassificationResult?)? onPillDetected,
    bool enableVibration = true,
  }) {
    _onBarcodeDetected = onBarcodeDetected;
    _onPillDetected = onPillDetected;
    _isVibrationEnabled = enableVibration;
    
    if (_cameraController == null || !_cameraController!.value.isInitialized) {
      print('âš ï¸ ì¹´ë©”ë¼ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ');
      return;
    }

    print('ğŸ”„ í†µí•© ì¸ì‹ ì‹œì‘ (ë°”ì½”ë“œ: ${onBarcodeDetected != null}, ì•Œì•½: ${onPillDetected != null})');
    _isBarcodeDetectionActive = onBarcodeDetected != null;
    _isPillDetectionActive = onPillDetected != null;
    
    // ê°ê° ë…ë¦½ì ì¸ íƒ€ì´ë¨¸ ì´ˆê¸°í™”
    _lastPillDetectionTime = null;
    _lastBarcodeDetectionTime = null;
    
    // ì´ë¯¸ì§€ ìŠ¤íŠ¸ë¦¼ ì‹œì‘
    _startImageStream();
    
    // ì¸ì‹ ì¤‘ ì§„ë™ ì‹œì‘ (1ì´ˆë§ˆë‹¤)
    if (_isVibrationEnabled) {
      _startRecognitionVibration();
    }
  }

  /// ì¸ì‹ ì¤‘ ì§„ë™ (1ì´ˆë§ˆë‹¤ ì§§ì€ ì§„ë™)
  void _startRecognitionVibration() {
    _stopRecognitionVibration(); // ê¸°ì¡´ íƒ€ì´ë¨¸ ì •ë¦¬
    
    _vibrationTimer = Timer.periodic(Duration(seconds: 1), (timer) {
      if (_isPillDetectionActive || _isBarcodeDetectionActive) {
        _vibrateLightly(); // ì§§ì€ ì§„ë™
      } else {
        timer.cancel();
      }
    });
  }

  /// ì¸ì‹ ì¤‘ ì§„ë™ ì¤‘ì§€
  void _stopRecognitionVibration() {
    _vibrationTimer?.cancel();
    _vibrationTimer = null;
  }

  /// ì§§ì€ ì§„ë™ (ì¸ì‹ ì¤‘) - HapticFeedback ì‚¬ìš©
  Future<void> _vibrateLightly() async {
    try {
      await HapticFeedback.lightImpact(); // ê°€ë²¼ìš´ ì§„ë™
    } catch (e) {
      print('âš ï¸ ì§„ë™ ì‹¤í–‰ ì˜¤ë¥˜: $e');
    }
  }

  /// ê°•í•œ ì§„ë™ (ì¸ì‹ ì™„ë£Œ) - 2ë²ˆ ì—°ì†
  Future<void> _vibrateSuccess() async {
    try {
      await HapticFeedback.heavyImpact(); // ê°•í•œ ì§„ë™
      await Future.delayed(Duration(milliseconds: 200)); // 200ms ê°„ê²©
      await HapticFeedback.heavyImpact(); // ê°•í•œ ì§„ë™
    } catch (e) {
      print('âš ï¸ ì„±ê³µ ì§„ë™ ì‹¤í–‰ ì˜¤ë¥˜: $e');
    }
  }

  /// ì´ë¯¸ì§€ ìŠ¤íŠ¸ë¦¼ ì‹œì‘ (ìµœì í™”ëœ ì²˜ë¦¬ ê°„ê²©)
  void _startImageStream() {
    if (_isImageStreamActive) return;
    
    print('ğŸ“¸ ì´ë¯¸ì§€ ìŠ¤íŠ¸ë¦¼ ì‹œì‘');
    _isImageStreamActive = true;
    
    _cameraController!.startImageStream((CameraImage image) async {
      if (!_isImageStreamActive) return;
      
      // ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬ (UI ë¸”ë¡œí‚¹ ë°©ì§€)
      Future.microtask(() async {
        await _processImage(image);
      });
    });
  }

  /// ì´ë¯¸ì§€ ì²˜ë¦¬ (ë°”ì½”ë“œ + ì•Œì•½) - ê°ê° ë…ë¦½ì ì¸ 1ì´ˆ ê°„ê²©
  Future<void> _processImage(CameraImage cameraImage) async {
    try {
      final now = DateTime.now();
      
      // 1. ë°”ì½”ë“œ ì¸ì‹ (ë…ë¦½ì ì¸ 1ì´ˆ ê°„ê²©)
      if (_isBarcodeDetectionActive && !_isBarcodeDetectionRunning) {
        if (_lastBarcodeDetectionTime == null || 
            now.difference(_lastBarcodeDetectionTime!).inMilliseconds >= 1000) {
          _lastBarcodeDetectionTime = now;
          await _detectBarcode(cameraImage);
        }
      }
      
      // 2. ì•Œì•½ ì¸ì‹ (ë…ë¦½ì ì¸ 1ì´ˆ ê°„ê²©)
      if (_isPillDetectionActive && !_isPillDetectionRunning) {
        if (_lastPillDetectionTime == null || 
            now.difference(_lastPillDetectionTime!).inMilliseconds >= 1000) {
          _lastPillDetectionTime = now;
          await _detectPill(cameraImage);
        }
      }
      
    } catch (e) {
      print('âŒ ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: $e');
    }
  }

  /// ML Kit ë°”ì½”ë“œ ì¸ì‹
  Future<void> _detectBarcode(CameraImage cameraImage) async {
    if (_isBarcodeDetectionRunning) return;
    
    _isBarcodeDetectionRunning = true;
    
    try {
      // CameraImageë¥¼ InputImageë¡œ ë³€í™˜
      final inputImage = _cameraImageToInputImage(cameraImage);
      if (inputImage == null) return;
      
      // ML Kit ë°”ì½”ë“œ ìŠ¤ìº”
      final List<Barcode> barcodes = await _barcodeScanner.processImage(inputImage);
      
      if (barcodes.isNotEmpty && _onBarcodeDetected != null) {
        final barcode = barcodes.first;
        if (barcode.rawValue != null) {
          print('ğŸ“¦ ë°”ì½”ë“œ ê°ì§€: ${barcode.rawValue}');
          
          // ì„±ê³µ ì§„ë™ ì‹¤í–‰
          if (_isVibrationEnabled) {
            await _vibrateSuccess();
          }
          
          _onBarcodeDetected!(barcode.rawValue!);
        }
      }
      
    } catch (e) {
      print('âŒ ë°”ì½”ë“œ ì¸ì‹ ì˜¤ë¥˜: $e');
    } finally {
      _isBarcodeDetectionRunning = false;
    }
  }

  /// TensorFlow Lite ì•Œì•½ ì¸ì‹
  Future<void> _detectPill(CameraImage cameraImage) async {
    if (_isPillDetectionRunning || _pillModel == null) return;
    
    _isPillDetectionRunning = true;
    
    try {
      print('ğŸ” ì•Œì•½ ì¸ì‹ ì‹œì‘');
      
      // CameraImageë¥¼ Float32Listë¡œ ë³€í™˜ (TensorFlow Liteìš©)
      final inputData = await _preprocessImageForTFLite(cameraImage);
      
      if (inputData != null) {
        print('âœ… ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì™„ë£Œ, TensorFlow Lite ì¶”ë¡  ì‹œì‘');
        
        try {
          // TensorFlow Lite ì¶”ë¡ 
          final outputData = await _runTFLiteInference(inputData);
          
          if (outputData != null && _onPillDetected != null) {
            final result = _processTFLiteOutput(outputData);
            
            if (result != null) {
              // ì—„ê²©í•œ ì„ê³„ê°’ ì ìš© (90% ì´ìƒ)
              if (result.confidence > 0.9) {
                print('ğŸ¯ ì•Œì•½ ì¸ì‹ ì„±ê³µ: ${result.className} (${(result.confidence * 100).toStringAsFixed(1)}%)');
                
                // ì„±ê³µ ì§„ë™ ì‹¤í–‰
                if (_isVibrationEnabled) {
                  await _vibrateSuccess();
                }
                
                _onPillDetected!(result);
              } else {
                print('ğŸ“‰ ì‹ ë¢°ë„ ë¶€ì¡±: ${(result.confidence * 100).toStringAsFixed(1)}%');
              }
            } else {
              print('âŒ ê²°ê³¼ ì²˜ë¦¬ ì‹¤íŒ¨');
            }
          } else {
            print('âŒ TensorFlow Lite ì¶”ë¡  ê²°ê³¼ê°€ null');
          }
          
        } catch (tfliteError) {
          print('âŒ TensorFlow Lite ì¶”ë¡  ì˜¤ë¥˜: $tfliteError');
        }
        
      } else {
        print('âŒ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨');
      }
      
    } catch (e) {
      print('âŒ ì•Œì•½ ì¸ì‹ ì „ì²´ ì˜¤ë¥˜: $e');
    } finally {
      _isPillDetectionRunning = false;
    }
  }

  /// ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (TensorFlow Liteìš©)
  Future<Float32List?> _preprocessImageForTFLite(CameraImage cameraImage) async {
    try {
      // ëª¨ë¸ ì •ë³´ì—ì„œ ì…ë ¥ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
      final targetWidth = _modelInfo!['input_width'] as int? ?? 224;
      final targetHeight = _modelInfo!['input_height'] as int? ?? 224;
      final mean = (_modelInfo!['mean'] as List?)?.cast<double>() ?? [0.485, 0.456, 0.406];
      final std = (_modelInfo!['std'] as List?)?.cast<double>() ?? [0.229, 0.224, 0.225];
      
      print('ğŸ” ì „ì²˜ë¦¬ ì‹œì‘ - íƒ€ê²Ÿ í¬ê¸°: ${targetWidth}x${targetHeight}');
      
      // YUV420ì„ RGBë¡œ ë³€í™˜
      final rgbBytes = await _convertYUV420ToRGBBytes(cameraImage);
      
      // RGB ë°ì´í„°ë¥¼ ì •ê·œí™”ëœ Float32Listë¡œ ë³€í™˜
      final inputData = _normalizeAndResize(
        rgbBytes, 
        cameraImage.width, 
        cameraImage.height,
        targetWidth, 
        targetHeight,
        mean,
        std
      );
      
      print('âœ… ì „ì²˜ë¦¬ ì™„ë£Œ - ë°ì´í„° í¬ê¸°: ${inputData.length}');
      return inputData;
      
    } catch (e) {
      print('âŒ ì „ì²˜ë¦¬ ì‹¤íŒ¨: $e');
      return null;
    }
  }

  /// RGB ë°ì´í„° ì •ê·œí™” ë° ë¦¬ì‚¬ì´ì¦ˆ
  Float32List _normalizeAndResize(
    Uint8List rgbData,
    int originalWidth,
    int originalHeight,
    int targetWidth,
    int targetHeight,
    List<double> mean,
    List<double> std
  ) {
    final Float32List result = Float32List(targetHeight * targetWidth * 3);
    
    final double scaleX = originalWidth / targetWidth;
    final double scaleY = originalHeight / targetHeight;
    
    int resultIndex = 0;
    
    for (int y = 0; y < targetHeight; y++) {
      for (int x = 0; x < targetWidth; x++) {
        // ì›ë³¸ ì¢Œí‘œ ê³„ì‚°
        final int sourceX = (x * scaleX).round().clamp(0, originalWidth - 1);
        final int sourceY = (y * scaleY).round().clamp(0, originalHeight - 1);
        final int sourceIndex = (sourceY * originalWidth + sourceX) * 3;
        
        // RGB ê°’ ì¶”ì¶œ ë° ì •ê·œí™”
        for (int c = 0; c < 3; c++) {
          if (sourceIndex + c < rgbData.length) {
            final double pixelValue = rgbData[sourceIndex + c] / 255.0;
            final double normalizedValue = (pixelValue - mean[c]) / std[c];
            result[resultIndex++] = normalizedValue;
          } else {
            result[resultIndex++] = (0.5 - mean[c]) / std[c]; // ê¸°ë³¸ê°’
          }
        }
      }
    }
    
    return result;
  }

  /// TensorFlow Lite ì¶”ë¡  ì‹¤í–‰
  Future<List<double>?> _runTFLiteInference(Float32List inputData) async {
    try {
      // ì…ë ¥ í…ì„œ ëª¨ì–‘ ê°€ì ¸ì˜¤ê¸°
      final inputTensor = _pillModel!.getInputTensors().first;
      final outputTensor = _pillModel!.getOutputTensors().first;
      
      print('ğŸ“Š ì…ë ¥ í…ì„œ ëª¨ì–‘: ${inputTensor.shape}');
      print('ğŸ“Š ì¶œë ¥ í…ì„œ ëª¨ì–‘: ${outputTensor.shape}');
      
      // ì…ë ¥ ë°ì´í„°ë¥¼ ì˜¬ë°”ë¥¸ ëª¨ì–‘ìœ¼ë¡œ ë³€í™˜
      final inputShape = inputTensor.shape;
      final reshapedInput = inputData.reshape(inputShape);
      
      // ì¶œë ¥ ë²„í¼ ì¤€ë¹„ - ì¶œë ¥ í…ì„œ ëª¨ì–‘ì— ë§ê²Œ 2ì°¨ì› ë°°ì—´ë¡œ ì¤€ë¹„
      final outputShape = outputTensor.shape;
      final List<List<double>> outputData = List.generate(
        outputShape[0], // ë°°ì¹˜ í¬ê¸° (ë³´í†µ 1)
        (i) => List.filled(outputShape[1], 0.0) // í´ë˜ìŠ¤ ìˆ˜
      );
      
      // ì¶”ë¡  ì‹¤í–‰
      _pillModel!.run(reshapedInput, outputData);
      
      print('ğŸ“Š ì¶”ë¡  ê²°ê³¼ í¬ê¸°: ${outputData[0].length}');
      print('ğŸ“Š ì¶”ë¡  ê²°ê³¼ ìƒ˜í”Œ: ${outputData[0].take(5).toList()}');
      
      // ì²« ë²ˆì§¸ ë°°ì¹˜ì˜ ê²°ê³¼ ë°˜í™˜
      return outputData[0];
      
    } catch (e) {
      print('âŒ TensorFlow Lite ì¶”ë¡  ì‹¤í–‰ ì‹¤íŒ¨: $e');
      
      // ëŒ€ì•ˆ: 1ì°¨ì› ì¶œë ¥ìœ¼ë¡œ ì¬ì‹œë„
      try {
        print('ğŸ”„ 1ì°¨ì› ì¶œë ¥ìœ¼ë¡œ ì¶”ë¡  ì¬ì‹œë„...');
        
        final inputTensor = _pillModel!.getInputTensors().first;
        final outputTensor = _pillModel!.getOutputTensors().first;
        
        // ì…ë ¥ì„ 4ì°¨ì› ë°°ì—´ë¡œ ì§ì ‘ êµ¬ì„±
        final inputShape = inputTensor.shape;
        final input = _createInputArray(inputData, inputShape);
        
        // ì¶œë ¥ì„ 1ì°¨ì› ë°°ì—´ë¡œ ì¤€ë¹„
        final outputShape = outputTensor.shape;
        final int totalOutputSize = outputShape.reduce((a, b) => a * b);
        final List<double> output = List.filled(totalOutputSize, 0.0);
        
        // ì¶”ë¡  ì‹¤í–‰
        _pillModel!.run(input, output);
        
        print('ğŸ“Š 1ì°¨ì› ì¶œë ¥ í¬ê¸°: ${output.length}');
        print('ğŸ“Š 1ì°¨ì› ì¶œë ¥ ìƒ˜í”Œ: ${output.take(5).toList()}');
        
        return output;
        
      } catch (e2) {
        print('âŒ 1ì°¨ì› ì¶œë ¥ ë°©ë²•ë„ ì‹¤íŒ¨: $e2');
        return null;
      }
    }
  }
  
  /// ì…ë ¥ ë°°ì—´ ìƒì„± (4ì°¨ì›)
  List<List<List<List<double>>>> _createInputArray(Float32List data, List<int> shape) {
    final int batch = shape[0];
    final int height = shape[1]; 
    final int width = shape[2];
    final int channels = shape[3];
    
    final result = List.generate(batch, (b) =>
      List.generate(height, (h) =>
        List.generate(width, (w) =>
          List.generate(channels, (c) {
            final index = b * height * width * channels + 
                         h * width * channels + 
                         w * channels + c;
            return index < data.length ? data[index] : 0.0;
          })
        )
      )
    );
    
    return result;
  }

  /// TensorFlow Lite ì¶œë ¥ ì²˜ë¦¬
  PillClassificationResult? _processTFLiteOutput(List<double> output) {
    try {
      if (output.isEmpty || _labels == null) {
        return null;
      }
      
      // Softmax ì ìš©
      final probabilities = _applySoftmax(output);
      
      // ìµœê³  í™•ë¥ ì˜ í´ë˜ìŠ¤ ì°¾ê¸°
      final maxIndex = _getMaxIndex(probabilities);
      final confidence = probabilities[maxIndex];
      
      print('ğŸ“Š ìµœê³  ì‹ ë¢°ë„: ${(confidence * 100).toStringAsFixed(1)}% (ì¸ë±ìŠ¤: $maxIndex)');
      
      // ìƒìœ„ 2ê°œ í´ë˜ìŠ¤ ê°„ ì°¨ì´ í™•ì¸
      final sortedProbs = [...probabilities]..sort((a, b) => b.compareTo(a));
      final confidenceDiff = sortedProbs[0] - sortedProbs[1];
      print('ğŸ“Š 1ìœ„-2ìœ„ ì°¨ì´: ${(confidenceDiff * 100).toStringAsFixed(1)}%');
      
      if (maxIndex < _labels!.length) {
        return PillClassificationResult(
          className: _labels![maxIndex],
          confidence: confidence,
          classIndex: maxIndex,
        );
      }
      
      return null;
      
    } catch (e) {
      print('âŒ ì¶œë ¥ ì²˜ë¦¬ ì‹¤íŒ¨: $e');
      return null;
    }
  }

  /// ì¹´ë©”ë¼ í¬ë§·ì„ InputImageFormatìœ¼ë¡œ ë³€í™˜
  InputImageFormat _getInputImageFormat(int rawFormat) {
    switch (rawFormat) {
      case 35: // ImageFormat.YUV_420_888
        return InputImageFormat.yuv420;
      case 17: // ImageFormat.NV21
        return InputImageFormat.nv21;
      case 842094169: // ImageFormat.YUV_420_888 on some devices
        return InputImageFormat.yuv420;
      default:
        return InputImageFormat.nv21; // ê¸°ë³¸ê°’
    }
  }

  /// CameraImageë¥¼ InputImageë¡œ ë³€í™˜ (ML Kitìš©) - ê°œì„ ëœ ë²„ì „
  InputImage? _cameraImageToInputImage(CameraImage cameraImage) {
    try {
      // CameraImage ë©”íƒ€ë°ì´í„° ì„¤ì •
      final camera = _cameraController!.description;
      
      // íšŒì „ ê°ë„ ê³„ì‚°
      final sensorOrientation = camera.sensorOrientation;
      InputImageRotation? rotation;
      
      switch (sensorOrientation) {
        case 0:
          rotation = InputImageRotation.rotation0deg;
          break;
        case 90:
          rotation = InputImageRotation.rotation90deg;
          break;
        case 180:
          rotation = InputImageRotation.rotation180deg;
          break;
        case 270:
          rotation = InputImageRotation.rotation270deg;
          break;
        default:
          rotation = InputImageRotation.rotation0deg;
      }
      
      // ì´ë¯¸ì§€ í¬ë§· í™•ì¸ ë° ì„¤ì •
      final format = _getInputImageFormat(cameraImage.format.raw);
      print('ğŸ“· CameraImage í¬ë§·: ${cameraImage.format.raw} -> $format');
      
      // ì´ë¯¸ì§€ ë°ì´í„° ì²˜ë¦¬ ë°©ì‹ ê°œì„ 
      Uint8List imageBytes;
      
      if (cameraImage.format.group == ImageFormatGroup.nv21 || 
          cameraImage.format.raw == 17) {
        // NV21 í¬ë§·ì˜ ê²½ìš° ì²« ë²ˆì§¸ planeë§Œ ì‚¬ìš©
        imageBytes = cameraImage.planes[0].bytes;
        print('ğŸ“· NV21 í¬ë§· ì‚¬ìš© - bytes í¬ê¸°: ${imageBytes.length}');
      } else {
        // ë‹¤ë¥¸ í¬ë§·ì˜ ê²½ìš° ëª¨ë“  plane í•©ì¹˜ê¸°
        final allBytes = WriteBuffer();
        for (final plane in cameraImage.planes) {
          allBytes.putUint8List(plane.bytes);
        }
        imageBytes = allBytes.done().buffer.asUint8List();
        print('ğŸ“· ë‹¤ë¥¸ í¬ë§· ì‚¬ìš© - í•©ì¹œ bytes í¬ê¸°: ${imageBytes.length}');
      }

      // InputImageMetadata ìƒì„±
      final inputImageData = InputImageMetadata(
        size: Size(cameraImage.width.toDouble(), cameraImage.height.toDouble()),
        rotation: rotation,
        format: format,
        bytesPerRow: cameraImage.planes.first.bytesPerRow,
      );

      return InputImage.fromBytes(
        bytes: imageBytes,
        metadata: inputImageData,
      );
      
    } catch (e) {
      print('âŒ InputImage ë³€í™˜ ì‹¤íŒ¨: $e');
      
      // ëŒ€ì•ˆ: ë” ê°„ë‹¨í•œ ë°©ë²•ìœ¼ë¡œ ì¬ì‹œë„
      try {
        print('ğŸ”„ ë‹¨ìˆœ ë³€í™˜ ë°©ë²•ìœ¼ë¡œ ì¬ì‹œë„...');
        
        // ê°€ì¥ ê¸°ë³¸ì ì¸ ë°©ë²•ìœ¼ë¡œ ë³€í™˜
        final bytes = cameraImage.planes[0].bytes;
        
        final inputImageData = InputImageMetadata(
          size: Size(cameraImage.width.toDouble(), cameraImage.height.toDouble()),
          rotation: InputImageRotation.rotation0deg,
          format: InputImageFormat.nv21, // ê°•ì œë¡œ NV21 ì‚¬ìš©
          bytesPerRow: cameraImage.planes[0].bytesPerRow,
        );

        return InputImage.fromBytes(
          bytes: bytes,
          metadata: inputImageData,
        );
        
      } catch (e2) {
        print('âŒ ë‹¨ìˆœ ë³€í™˜ë„ ì‹¤íŒ¨: $e2');
        return null;
      }
    }
  }

  /// YUV420ì„ RGB Uint8Listë¡œ ë³€í™˜ (í”Œë«í¼ë³„ ì²˜ë¦¬) - NV21 ì§€ì› ì¶”ê°€
  Future<Uint8List> _convertYUV420ToRGBBytes(CameraImage cameraImage) async {
    final int width = cameraImage.width;
    final int height = cameraImage.height;
    
    final Uint8List yPlane = cameraImage.planes[0].bytes;
    
    // NV21 í¬ë§· ì²˜ë¦¬ (Androidì—ì„œ ì£¼ë¡œ ì‚¬ìš©)
    if (cameraImage.format.group == ImageFormatGroup.nv21 || 
        cameraImage.format.raw == 17) {
      
      if (cameraImage.planes.length >= 2) {
        // NV21: Y plane + interleaved UV plane
        final Uint8List uvPlane = cameraImage.planes[1].bytes;
        return _convertNV21ToRGB(yPlane, uvPlane, width, height);
      } else {
        // Y planeë§Œ ìˆìœ¼ë©´ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ì²˜ë¦¬
        return _convertGrayscaleToRGB(yPlane);
      }
    }
    
    // YUV420 í¬ë§· ì²˜ë¦¬
    if (cameraImage.planes.length < 3) {
      // Y ì±„ë„ë§Œ ìˆë‹¤ë©´ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
      return _convertGrayscaleToRGB(yPlane);
    }
    
    final Uint8List uPlane = cameraImage.planes[1].bytes;
    final Uint8List vPlane = cameraImage.planes[2].bytes;
    
    // í”Œë«í¼ë³„ í”½ì…€ ìŠ¤íŠ¸ë¼ì´ë“œ ì²˜ë¦¬
    int uvPixelStride = 1; // ê¸°ë³¸ê°’
    
    // Android: bytesPerPixel ì‚¬ìš© (pixelStrideì™€ ë™ì¼ ê°œë…)
    if (cameraImage.planes[1].bytesPerPixel != null) {
      uvPixelStride = cameraImage.planes[1].bytesPerPixel!;
      print('ğŸ“± Android ê°ì§€ - UV pixelStride: $uvPixelStride');
    } 
    // iOS: width/height ì •ë³´ í™œìš©
    else if (cameraImage.planes[1].width != null && cameraImage.planes[1].height != null) {
      uvPixelStride = 1; // iOSëŠ” ë³´í†µ ì—°ì†ì ìœ¼ë¡œ ì €ì¥
      print('ğŸ iOS ê°ì§€ - UV ì—°ì† ì €ì¥ ë°©ì‹');
    }
    // ê¸°íƒ€ í”Œë«í¼: bytesPerRowë¡œ ì¶”ì •
    else {
      final int uvBytesPerRow = cameraImage.planes[1].bytesPerRow;
      uvPixelStride = uvBytesPerRow > (width ~/ 2) ? 2 : 1;
      print('ğŸ”§ ê¸°íƒ€ í”Œë«í¼ - UV pixelStride ì¶”ì •: $uvPixelStride');
    }
    
    return _convertYUV420ToRGB(yPlane, uPlane, vPlane, width, height, uvPixelStride);
  }

  /// NV21ì„ RGBë¡œ ë³€í™˜
  Uint8List _convertNV21ToRGB(Uint8List yPlane, Uint8List uvPlane, int width, int height) {
    final List<int> rgbBytes = [];
    
    for (int y = 0; y < height; y++) {
      for (int x = 0; x < width; x++) {
        final int yIndex = y * width + x;
        final int uvIndex = ((y ~/ 2) * (width ~/ 2) + (x ~/ 2)) * 2;
        
        // Y ê°’ (ë°ê¸°)
        final int yValue = yIndex < yPlane.length ? yPlane[yIndex] : 128;
        
        // UV ê°’ (ìƒ‰ì°¨) - NV21ì€ V,U ìˆœì„œë¡œ interleaved
        int uValue = 128, vValue = 128; // ê¸°ë³¸ê°’
        
        if (uvIndex + 1 < uvPlane.length) {
          vValue = uvPlane[uvIndex];     // V (Cr)
          uValue = uvPlane[uvIndex + 1]; // U (Cb)
        }
        
        // YUV to RGB ë³€í™˜
        final int r = (yValue + 1.402 * (vValue - 128)).round().clamp(0, 255);
        final int g = (yValue - 0.344136 * (uValue - 128) - 0.714136 * (vValue - 128)).round().clamp(0, 255);
        final int b = (yValue + 1.772 * (uValue - 128)).round().clamp(0, 255);
        
        rgbBytes.addAll([r, g, b]);
      }
    }
    
    return Uint8List.fromList(rgbBytes);
  }

  /// YUV420ì„ RGBë¡œ ë³€í™˜ (ë¶„ë¦¬ëœ U, V plane)
  Uint8List _convertYUV420ToRGB(
    Uint8List yPlane, 
    Uint8List uPlane, 
    Uint8List vPlane, 
    int width, 
    int height, 
    int uvPixelStride
  ) {
    final List<int> rgbBytes = [];
    
    for (int y = 0; y < height; y++) {
      for (int x = 0; x < width; x++) {
        final int yIndex = y * width + x;
        final int uvIndex = (y ~/ 2) * (width ~/ 2) + (x ~/ 2);
        
        // Y ê°’ (ë°ê¸°)
        final int yValue = yIndex < yPlane.length ? yPlane[yIndex] : 128;
        
        // UV ê°’ (ìƒ‰ì°¨) - í”Œë«í¼ë³„ ì ‘ê·¼ ë°©ì‹
        int uValue = 128, vValue = 128; // ê¸°ë³¸ê°’ (ì¤‘ì„± íšŒìƒ‰)
        
        final int uOffset = uvIndex * uvPixelStride;
        final int vOffset = uvIndex * uvPixelStride;
        
        if (uOffset < uPlane.length) {
          uValue = uPlane[uOffset];
        }
        if (vOffset < vPlane.length) {
          vValue = vPlane[vOffset];
        }
        
        // YUV to RGB ë³€í™˜ (ITU-R BT.601 í‘œì¤€)
        final int r = (yValue + 1.402 * (vValue - 128)).round().clamp(0, 255);
        final int g = (yValue - 0.344136 * (uValue - 128) - 0.714136 * (vValue - 128)).round().clamp(0, 255);
        final int b = (yValue + 1.772 * (uValue - 128)).round().clamp(0, 255);
        
        rgbBytes.addAll([r, g, b]);
      }
    }
    
    return Uint8List.fromList(rgbBytes);
  }

  /// ê·¸ë ˆì´ìŠ¤ì¼€ì¼ì„ RGBë¡œ ë³€í™˜ (Y ì±„ë„ë§Œ ìˆì„ ë•Œ)
  Uint8List _convertGrayscaleToRGB(Uint8List yPlane) {
    final List<int> rgbBytes = [];
    
    for (int i = 0; i < yPlane.length; i++) {
      final int grayValue = yPlane[i];
      rgbBytes.addAll([grayValue, grayValue, grayValue]); // R=G=B
    }
    
    return Uint8List.fromList(rgbBytes);
  }

  /// Softmax í•¨ìˆ˜ (ì‹ ë¢°ë„ ê³„ì‚°ìš©)
  List<double> _applySoftmax(List<double> logits) {
    if (logits.isEmpty) return [];
    
    // ìˆ˜ì¹˜ ì•ˆì •ì„±ì„ ìœ„í•´ ìµœëŒ€ê°’ ë¹¼ê¸°
    final maxLogit = logits.reduce((a, b) => a > b ? a : b);
    final expValues = logits.map((x) => math.exp(x - maxLogit)).toList();
    final sumExp = expValues.fold(0.0, (a, b) => a + b);
    
    // 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
    if (sumExp == 0.0 || sumExp.isNaN || sumExp.isInfinite) {
      return List.filled(logits.length, 1.0 / logits.length);
    }
    
    // ì•ˆì „í•œ ë‚˜ëˆ„ê¸° ì—°ì‚°
    return expValues.map((x) {
      final result = x / sumExp;
      return result.isNaN || result.isInfinite ? 0.0 : result;
    }).toList();
  }

  /// ìµœëŒ€ê°’ ì¸ë±ìŠ¤ ì°¾ê¸°
  int _getMaxIndex(List<double> scores) {
    double maxScore = scores[0];
    int maxIndex = 0;
    
    for (int i = 1; i < scores.length; i++) {
      if (scores[i] > maxScore) {
        maxScore = scores[i];
        maxIndex = i;
      }
    }
    
    return maxIndex;
  }

  /// ì¸ì‹ ì¤‘ì§€
  void stopDetection() {
    print('ğŸ›‘ ëª¨ë“  ì¸ì‹ ì¤‘ì§€');
    _isPillDetectionActive = false;
    _isBarcodeDetectionActive = false;
    _isPillDetectionRunning = false;
    _isBarcodeDetectionRunning = false;
    
    // ì§„ë™ ì¤‘ì§€
    _stopRecognitionVibration();
    
    if (_isImageStreamActive) {
      _isImageStreamActive = false;
      try {
        _cameraController?.stopImageStream();
      } catch (e) {
        print('âš ï¸ ì´ë¯¸ì§€ ìŠ¤íŠ¸ë¦¼ ì¤‘ì§€ ì˜¤ë¥˜: $e');
      }
    }
  }

  /// í”Œë˜ì‹œ í† ê¸€
  void toggleFlash() {
    try {
      if (_cameraController != null) {
        print('ğŸ’¡ í”Œë˜ì‹œ í† ê¸€');
        final currentFlashMode = _cameraController!.value.flashMode;
        final newFlashMode = currentFlashMode == FlashMode.off 
          ? FlashMode.torch 
          : FlashMode.off;
        _cameraController!.setFlashMode(newFlashMode);
      }
    } catch (e) {
      print('âŒ í”Œë˜ì‹œ í† ê¸€ ì˜¤ë¥˜: $e');
    }
  }

  /// ì§„ë™ í™œì„±í™”/ë¹„í™œì„±í™”
  void setVibrationEnabled(bool enabled) {
    _isVibrationEnabled = enabled;
    if (!enabled) {
      _stopRecognitionVibration();
    } else if (_isPillDetectionActive || _isBarcodeDetectionActive) {
      _startRecognitionVibration();
    }
  }

  /// ì •ë¦¬
  Future<void> dispose() async {
    print('ğŸ—‘ï¸ ì¹´ë©”ë¼ ì •ë¦¬');
    
    stopDetection();
    
    try {
      await _barcodeScanner.close();
    } catch (e) {
      print('âš ï¸ ë°”ì½”ë“œ ìŠ¤ìºë„ˆ ì •ë¦¬ ì˜¤ë¥˜: $e');
    }
    
    try {
      if (_cameraController?.value.isStreamingImages == true) {
        await _cameraController!.stopImageStream();
      }
      await _cameraController?.dispose();
      _cameraController = null;
    } catch (e) {
      print('âš ï¸ ì¹´ë©”ë¼ ì •ë¦¬ ì˜¤ë¥˜: $e');
    }
    
    try {
      _pillModel?.close();
    } catch (e) {
      print('âš ï¸ TensorFlow Lite ëª¨ë¸ ì •ë¦¬ ì˜¤ë¥˜: $e');
    }
    
    _pillModel = null;
    _labels = null;
    _modelInfo = null;
    _onBarcodeDetected = null;
    _onPillDetected = null;
  }
}

/// ì•Œì•½ ë¶„ë¥˜ ê²°ê³¼
class PillClassificationResult {
  final String className;
  final double confidence;
  final int classIndex;
  
  PillClassificationResult({
    required this.className,
    required this.confidence,
    required this.classIndex,
  });
  
  @override
  String toString() => '$className (${(confidence * 100).toStringAsFixed(1)}%)';
}

/// ì¹´ë©”ë¼ ì´ˆê¸°í™” ê²°ê³¼
class CameraInitResult {
  final bool isSuccess;
  final bool isPermissionDenied;
  final String? errorMessage;

  CameraInitResult._({
    required this.isSuccess,
    required this.isPermissionDenied,
    this.errorMessage,
  });

  factory CameraInitResult.success() => CameraInitResult._(
        isSuccess: true,
        isPermissionDenied: false,
      );

  factory CameraInitResult.permissionDenied() => CameraInitResult._(
        isSuccess: false,
        isPermissionDenied: true,
        errorMessage: 'ì¹´ë©”ë¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.',
      );

  factory CameraInitResult.error(String message) => CameraInitResult._(
        isSuccess: false,
        isPermissionDenied: false,
        errorMessage: message,
      );

  String getUserMessage() {
    if (isSuccess) return 'ì¹´ë©”ë¼ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤';
    return errorMessage ?? 'ì¹´ë©”ë¼ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤';
  }
}

// Float32List reshape í™•ì¥ ë©”ì„œë“œ
extension Float32ListReshape on Float32List {
  List<List<List<List<double>>>> reshape(List<int> shape) {
    if (shape.length != 4) {
      throw ArgumentError('Shape must have 4 dimensions for NHWC format');
    }
    
    final int n = shape[0]; // batch
    final int h = shape[1]; // height  
    final int w = shape[2]; // width
    final int c = shape[3]; // channels
    
    final result = List.generate(n, (batch) =>
      List.generate(h, (height) =>
        List.generate(w, (width) =>
          List.generate(c, (channel) {
            final index = batch * h * w * c + height * w * c + width * c + channel;
            return index < length ? this[index].toDouble() : 0.0;
          })
        )
      )
    );
    
    return result;
  }
}

// List reshape í™•ì¥ ë©”ì„œë“œ  
extension ListReshape on List<double> {
  List<List<List<List<double>>>> reshape(List<int> shape) {
    if (shape.length != 4) {
      throw ArgumentError('Shape must have 4 dimensions');
    }
    
    final int n = shape[0]; // batch
    final int h = shape[1]; // height
    final int w = shape[2]; // width  
    final int c = shape[3]; // channels
    
    final result = List.generate(n, (batch) =>
      List.generate(h, (height) =>
        List.generate(w, (width) =>
          List.generate(c, (channel) {
            final index = batch * h * w * c + height * w * c + width * c + channel;
            return index < length ? this[index] : 0.0;
          })
        )
      )
    );
    
    return result;
  }
}